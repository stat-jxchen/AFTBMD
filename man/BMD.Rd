% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{BMD}
\alias{BMD}
\title{Blockwise Majorization Descent Algorithm}
\usage{
BMD(BS, KM, ny, h1, h2, group, M, lambda1, lambda2, penalty, eps)
}
\arguments{
\item{BS}{a matrix, the columns of which should be the predicted value
of the orthogonal B-spline base at the corresponding point for continuous
variables or standardized data for discrete variables.}

\item{KM}{a vector, the Kaplan-Meier weights vector.}

\item{ny}{a vector, the logarithm survival time after sorting.}

\item{h1}{a vector, the first entry of Hessian matrix according to every group.}

\item{h2}{a vector, the max eigenvalue of Hessian matrix according to every group except the first entry.
In particular, if a group only contains a single column, such as discrete variable, the
corresponding element should be assign to 0.}

\item{group}{a vector, the columns of \code{BS} in each group.}

\item{M}{a number, the maximum times of iteration.}

\item{lambda1}{a number, the penalty factor corresponding to the first entry of every group.}

\item{lambda2}{a number, the penalty factor corresponding to remaining entries of every group.}

\item{penalty}{a character, which indicates the penalty function, and can be one of "glasso", "gscad" and "gmcp".}

\item{eps}{a number, the tolerance error.}
}
\value{
The optimal solution vector which minimizes the weighted least squares loss function
with specific penalty.
}
\description{
This function returns the optimal solution vector according to the BMD algorithm.
}
\details{
(ToDo) Refer to the method in initial paper and the method in this paper.
}
\examples{
x <- SimuData$x
n <- nrow(x)
d <- ncol(x)
y <- SimuData$y
M <- 200 # maximum iter time
m <- 4
p <- 3 # the degree of the piecewise polynomial
df <- m + p # degree of freedom
dfset <- rep(df, d) # record the df of every group
nIknots <- m - 1 # the number of knots
Boundary.knots <- range(-1, 1)
knots <- seq.int(from = (-1), to = 1, length.out = nIknots + 2)[-c(1, nIknots + 2)]
ny <- sort(y)
nx <- x[order(y), ]
KM <- KMweight(SimuData)
BS <- numeric(0)
for(i in 1:d){
  BS1 <- splines2::bSpline(nx[, i], degree = p, knots = knots,
  Boundary.knots = Boundary.knots, intercept = TRUE)
  BS2 <- nx[, i] * bar_bs(BS1, d)
  BS <- cbind(BS, BS2)}

h <- calculate_V(BS, KM, n)
hj <- hj2 <- rep(0, d)
gl <- c(0,cumsum(dfset))
for(i in 1:d){
  start <- gl[i]+1
  hj[i] <- h[start,start]
  start <- gl[i]+2
  end <- gl[i+1]
  h1 <- h[start:end, start:end]
  hj2[i] <- max(eigen(h1)$value)}
# rough tuning parameter grid
lambda1 <- seq(0.01, 0.014, 0.002)
lambda2 <- seq(0.01, 0.014, 0.002)
lg.lambda1 <- length(lambda1)
lg.lambda2 <- length(lambda2)
# storage the tuning results
theta_est <- array(0, c(lg.lambda1, lg.lambda2, sum(dfset)))
lf_value <- matrix(0, lg.lambda1, lg.lambda2)
for(j1 in 1:lg.lambda1){
  for(j2 in 1:lg.lambda2){
    theta_est[j1,j2,] <- BMD(BS, KM, ny, hj, hj2, dfset, M, lambda1[j1],
                             lambda2[j2], "gscad", 1e-4)
    lf_value[j1,j2] <- sum((ny - BS \%*\% theta_est[j1, j2, ])^2 * KM)/2
  }
}
# select the best estimator and record the best regularization parameters pair
theta_obj <- selection(theta_est, n, lf_value)
theta_hat <- theta_obj$theta_est
id <- theta_obj$id
lambda_pair <- c(lambda1[id[1]], lambda2[id[2]])
}
